# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11WLuPn9qQzhsN8M3232lOHe25su_-13a
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.models import Model
from sklearn.utils import class_weight
from tensorflow.keras.applications import EfficientNetB0
from PIL import Image
from tensorflow.keras.preprocessing import image

from google.colab import files
import zipfile
import os

# Upload the zip
uploaded = files.upload()  # Upload e.g., roman_data.zip

# Extract it
for fname in uploaded.keys():
    if fname.endswith('.zip'):
        with zipfile.ZipFile(fname, 'r') as zip_ref:
            zip_ref.extractall()
        print(" Extracted:", fname)

print(os.getcwd()) #Print the current working directory
print(os.listdir()) # List the files and folders in the current directory

train_dir = 'Dataset/train'
val_dir = 'Dataset/val'
test_dir = 'Dataset/test'

# Image Size
img_size = (64, 64)
batch_size = 32

# Data Generators
train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15,
                                   width_shift_range=0.1, height_shift_range=0.1,
                                   zoom_range=0.1, shear_range=0.1)

val_test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(train_dir, target_size=img_size, class_mode='categorical', batch_size=batch_size)
val_gen = val_test_datagen.flow_from_directory(val_dir, target_size=img_size, class_mode='categorical', batch_size=batch_size)
test_gen = val_test_datagen.flow_from_directory(test_dir, target_size=img_size, class_mode='categorical', batch_size=1, shuffle=False)

# CNN Model
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(*img_size, 3)),
    BatchNormalization(),
    MaxPooling2D(),
    Dropout(0.2),

    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(),
    Dropout(0.3),

    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(),
    Dropout(0.4),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')  # 3 classes: I, V, X
])

model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])

# Training
history = model.fit(train_gen, validation_data=val_gen, epochs=20)

# Evaluation
test_loss, test_acc = model.evaluate(test_gen)
print(f"Test Accuracy: {test_acc:.2f}")

# Predictions & Report
preds = model.predict(test_gen)
y_pred = np.argmax(preds, axis=1)
y_true = test_gen.classes

print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=test_gen.class_indices.keys(), yticklabels=test_gen.class_indices.keys(), cmap="Blues")
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

IMG_SIZE = (128, 128)  # You can keep this same if you're already using 128x128

# Update your ImageDataGenerators to use this size:
train_gen = train_datagen.flow_from_directory(train_dir, target_size=IMG_SIZE, class_mode='categorical')
val_gen = val_test_datagen.flow_from_directory(val_dir, target_size=IMG_SIZE, class_mode='categorical')
test_gen = val_test_datagen.flow_from_directory(test_dir, target_size=IMG_SIZE, class_mode='categorical', shuffle=False)

base_model = MobileNetV2(input_shape=(*IMG_SIZE, 3), include_top=False, weights='imagenet')
base_model.trainable = False  # freeze for transfer learning

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
predictions = Dense(10, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(learning_rate=0.0005),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=5  # keep low first, then we'll fine-tune
)

# Unfreeze top 30 layers for fine-tuning
for layer in base_model.layers[-30:]:
    layer.trainable = True

# Recompile with a lower learning rate for fine-tuning
model.compile(optimizer=Adam(learning_rate=1e-5),  # Smaller LR is crucial here
              loss='categorical_crossentropy',
              metrics=['accuracy'])

fine_tune_history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=5  # You can do more depending on results
)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=15,       # slight rotations
    width_shift_range=0.1,   # slight horizontal shift
    height_shift_range=0.1,  # slight vertical shift
    shear_range=0.1,
    zoom_range=0.1,
    brightness_range=[0.8,1.2],  # simulate lighting changes
    horizontal_flip=False,   # Roman numerals shouldn't flip!
    fill_mode='nearest'
)

# val and test should remain clean
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Reload generators with new augmentations
train_gen = train_datagen.flow_from_directory(train_dir, target_size=(128, 128), class_mode='categorical')
val_gen = val_test_datagen.flow_from_directory(val_dir, target_size=(128, 128), class_mode='categorical')
test_gen = val_test_datagen.flow_from_directory(test_dir, target_size=(128, 128), class_mode='categorical', shuffle=False)

history_aug = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=5
)

# Predict
preds = model.predict(test_gen)
y_pred = np.argmax(preds, axis=1)
y_true = test_gen.classes
labels = list(test_gen.class_indices.keys())

# Classification Report
print(classification_report(y_true, y_pred, target_names=labels))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

model.compile(
    loss=tensorflow.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),
    optimizer=tensorflow.keras.optimizers.Adam(learning_rate=1e-4),
    metrics=['accuracy']
)

# Get class labels from the training generator
class_labels = list(train_gen.class_indices.keys())
y_train = train_gen.classes  # numeric labels

# Compute class weights
weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)

# Map to dictionary
class_weights = dict(enumerate(weights))
print("Class weights:", class_weights)

history = model.fit(
    train_gen,
    epochs=15,
    validation_data=val_gen,
    class_weight=class_weights
)

# Predict again
preds = model.predict(test_gen)
y_pred = np.argmax(preds, axis=1)
y_true = test_gen.classes

# Classification report
print(classification_report(y_true, y_pred, target_names=test_gen.class_indices.keys()))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=test_gen.class_indices.keys(), yticklabels=test_gen.class_indices.keys())
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

uploaded = files.upload()

for fname in uploaded.keys():
    img = Image.open(fname).convert('RGB')
    img = img.resize((224, 224))  # ✅ match model input
    img_array = image.img_to_array(img)
    img_array = img_array / 255.0  # ✅ match training normalization
    img_array = np.expand_dims(img_array, axis=0)

    # Predict
    prediction = model.predict(img_array)
    predicted_class = np.argmax(prediction)
    class_labels = list(test_gen.class_indices.keys())
    predicted_label = class_labels[predicted_class]

    # Show image and result
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Predicted Roman Numeral: {predicted_label}")
    plt.show()